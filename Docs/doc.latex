\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{nameref}
\usepackage{pifont}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage{listings}
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{red},
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
  keywordstyle=\color{blue}
}
\usepackage{fourier}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\title{MPI interversion compability with Singularity containers over Finis Terrae II using an InfiniBand network}

\author{Manuel Simon Novoa}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Enter a short summary here. What topic do you want to investigate and why? What experiment did you perform? What were your main results and conclusion?
\end{abstract}

\section{Introduction 5 lines to max 1/2 page}
\label{sec:introduction}

VÃ­ctor says: Hola!

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce mattis mauris nec neque lacinia mattis. Mauris tincidunt sapien quis tortor malesuada ullamcorper. Curabitur quis mauris sed odio viverra facilisis vel a nibh. Proin et vehicula est. In dictum blandit odio sit amet laoreet. Integer blandit purus id dolor sollicitudin tempor. Praesent turpis erat, aliquet ac tellus nec, iaculis laoreet augue. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut malesuada magna velit, non varius dui lacinia ut. Nulla facilisi. Nulla vulputate malesuada nisl. Mauris mauris est, consequat id condimentum nec, viverra quis est. Curabitur fermentum, sem sed lacinia auctor, nisi tellus interdum tellus, a suscipit libero libero a nulla. Praesent eu felis volutpat, viverra metus sit amet, viverra purus. In volutpat porttitor velit vel efficitur.

In a auctor ligula. Proin finibus quam a nisl molestie malesuada. Donec a enim purus. Mauris vel nisl ultrices, fringilla diam nec, volutpat tortor. Fusce malesuada, nisi egestas lobortis malesuada, nibh odio faucibus nulla, quis porttitor ligula ante et mauris. Nullam sed nisl interdum, fermentum turpis ut, dapibus orci. Maecenas venenatis arcu mauris, ut ultrices sapien venenatis vitae. Fusce semper sed tellus in commodo. In ornare erat vitae tincidunt euismod. Vestibulum nisi ex, fringilla sit amet dictum vel, venenatis feugiat tellus. Pellentesque eu nibh faucibus, posuere magna ac, volutpat sem.

Mauris ut lobortis odio, sed hendrerit nulla. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas lacinia ac leo ac placerat. In fringilla dolor vel ipsum rutrum, at finibus libero posuere. Integer eu varius elit. Aliquam erat volutpat. Nulla sed risus libero. Aliquam elementum eleifend sapien eu tristique.  \cite{nano3}.

\section{Used technologies: what, why and how}
\label{sec:technologies}

TODO: writte a previous intro

\subsection{A brief introduction to Singularity}
Lorem ipsum

\subsection{Variables of the development environment}
How the containers will be done? Why? Tests...
\paragraph{Open MPI}
Selected versions... why $\rightarrow$ FT2
\paragraph{Intel MPI}
Same...

\subsection{Research of the development environment}
Bootstrap files and its creation. Short intro and raised possibilities.
\paragraph{Using the default version included in different Linux distributions}
Trying ubuntu, debian and red hat distros. Using policy command.
\paragraph{Installing different OpenMPI versions on Ubuntu 16.10 containers}
How is the software installed?
Bootstrap files and scripts for its creation (automation)

\subsection{Final containers creation proccess}
Example of a bootstrap definition file

\section{Study environment: availabilities and limitations}
\label{sec:environment}
something...
\subsection{What's the 'objetos de estudio'}

\begin{table}[h]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 &  &  &  &  &  \\ \hline
2.0.0 &  &  &  &  &  \\ \hline
2.0.1 &  &  &  &  &  \\ \hline
2.0.2 &  &  &  &  &  \\ \hline
2.1.1 &  &  &  &  & \\ \hline
\end{tabular}
\end{table}


\subsection{Available compilers}
gnu, intel...
\begin{figure}[H]
\centering\includegraphics[width=0.6\linewidth]{cubo-pruebas-sin-nombre-final}
\caption{Figure caption}
\end{figure}
\begin{figure}[H]
\centering\includegraphics[width=0.6\linewidth]{desglose-cubo}
\caption{Figure caption}
\end{figure}

\section{Approaches of the problem and development}
\label{sec:approach}
Reference to \nameref{sec:mixing} \newline
Reference to \nameref{sec:linking}

\section{Mixing MPI versions}
\label{sec:mixing}
\paragraph{Trying 'by default'}
\subparagraph{Test apps: ring, hellowo}
hellowo fue empleado en las de compilador intel

\subsection{mpi run}
\begin{table}[H]
\centering
\caption{mpirun mixing different compilers, 1 and 2 nodes}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.0 & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.1 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.2 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} \\ \hline
2.1.1 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{mpirun Intel 1 and 2 nodes, hellowo}
\label{my-label}
\begin{tabular}{|r|c|c|}
\hline
\multicolumn{1}{|c|}{Container Intel MPI version} & \multicolumn{2}{c|}{FT2 Intel MPI version} \\ \hline
 & 5.1 & 2017 \\ \hline
5.1 &  &  \\ \hline
2017 & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} \\ \hline
\end{tabular}
\end{table}

\subsection{srun (slurm)}
\begin{table}[H]
\centering
\caption{srun front FT2, different compilers, 1 node}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.0 & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.1 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.2 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} \\ \hline
2.1.1 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \color[HTML]{006600}{\cmark} \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{srun front FT2, different compilers, 2 nodes}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.0 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.1 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.0.2 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
2.1.1 & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} & \textcolor{red}{\xmark} \\ \hline
\end{tabular}
\end{table}
When this test was done, false positives were obtained for every one-to-one match. In those cases, when the ring program was executed, it did an execution for every node, but none of them could "see" the others. Because of this reason, the ring call was executed as many instances as nodes were indicated, having each of them just one process per ring. So, parallel communication was not obtained.


\section{Binding libraries and its dependencies}
\label{sec:linking}
\subsection{mpi run}
\subsection{srun (slurm)}
\paragraph{ldd}
\subparagraph{Tests apps: ring, hellowo}

\begin{table}[H]
\centering
\caption{srun ring 2 nodes, mixing compilers}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 & \color[HTML]{006600}{\cmark}  & \color[HTML]{FF4F00}{\danger} & \color[HTML]{FF4F00}{\danger} & \color[HTML]{FF4F00}{\danger} & \color[HTML]{FF4F00}{\danger} \\ \hline
2.0.0 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} \\ \hline
2.0.1 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} \\ \hline
2.0.2 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} \\ \hline
2.1.1 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} \\ \hline
\end{tabular}
\end{table}
As can be seen at the table above, once all the involved libraries and its dependencies were satisfied, the test program, ring, could be executed under any container-FT2 OpenMPI mix. However, if the 1.10.2 OpenMPI container is used with a superior OpenMPI version outside, it will show a warning prompt, making reference to  different sizes in symbols (e.g. Symbol 'ompi\_mpi\_comm\_world' has different size in shared object, consider re-linking). Due to this, future real world applications could not work properly or crash.

\subparagraph{Real world apps: Feel++, XH5For}
Once the test applications passed; real world applications, build inside already created containers, were proved. For this reason, the OpenMPI version contained could not be changed.
\begin{table}[H]
\centering
\caption{Feel++}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} \\ \hline
\end{tabular}
\end{table}
As can be seen, in this test, a containerized 1.10.2 OpenMPI version worked over 1.10.2, 2.0.0, 2.0.1 and 2.0.2 outside OpenMPI versions. Nevertheless, 2.1.1 outside OpenMPI did not work. Most probably this is because the latest version employs an Intel compiler, and not a GNU compiler as the other ones. So, for the very first time, a compiler dependency was discover. In order to get reduce noise as much as possible, from this moment, they are not taken into account OpenMPI versions that have not been compiled with GNU compilers.

\begin{table}[H]
\centering
\caption{XH5For}
\label{my-label}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Container OpenMPI version} & \multicolumn{5}{c|}{FT2 OpenMPI version} \\ \hline
\multicolumn{1}{|c|}{} & 1.10.2 & 2.0.0 & 2.0.1 & 2.0.2 & 2.1.1 \\ \hline
1.10.2 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} \\ \hline
2.1.1 & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \color[HTML]{006600}{\cmark} & \textcolor{red}{\xmark} \\ \hline
\end{tabular}
\end{table}

\section{Benchmarks}


One of the biggest containers' advantages is its theoretical efficient and lightweight operating mode. When using the same kernel as the host machine, and avoiding replication as much as possible, makes of containers virtualization a great solution for HPC programs execution.


Nevertheless, until this lightness is verified in our work environment, we will not stop talking about a completely theoretical framework. Because of this, some benchmarks will be done, to verify this in a practical way.


So, the objective of the following benchmark tests is no other than proof that containers development will allow a great response time.
\subsection{InfiniBand network benchmarks: OSU microbenchmarks}
Since the goal of this document is the description of how to use Singularity containers employing different versions of MPI, one of the most interesting benchmarks that can be done is the use of the network. We are not talking about a network that connects with the outside, but an internode network that allows the communication of the different processors for a correct parallel operation. For this purpose, FinisTerrae II, as well as many others clusters, uses an InfiniBand network. InfiniBand is a computer-networking communications standard used in high-performance computing that features very high throughput and very low latency. It is used for data interconnect both among and within computers.


So, now the Singularity containers are using MPI, we will check if they are making use of the InfiniBand network for that. 


The selected bechmarks for this practical approach are the \textit{OSU microbenchmarks}\cite{osu-microbenchmarks}, belonging to \textit{The Ohio State University}, what will allow us to measure some interesting parameters, such as latency or bandwidth. Once the tests were done, we will check if the obtained results belong to a reasonable InfiniBand network parameters.


When the \textit{OSU microbenchmark} pack is downloaded in our container, it can be compilled and installed easily thanks to the included makefile.
\begin{lstlisting}[language=bash,caption={Installing OSU microbenchmarks}]
sudo singularity exec -w CONTAINER_NAME.img ./configure CC=/path/to/special/mpicc --prefix=<path-to-install> && make && make install
\end{lstlisting}


Once the \textit{OSU microbenchmarks} are installed, we can find a battery of test in the directory \verb|/usr/bin/libexec/osu-micro-benchmarks| (default installation directory). This battery of benchmarks is composed by the following:
\begin{lstlisting}[language=bash,caption={OSU microbenchmarks}]
.
`-- osu-micro-benchmarks
    `-- mpi
        |-- collective
        |   |-- osu_allgather
        |   |-- osu_allgatherv
        |   |-- osu_allreduce
        |   |-- osu_alltoall
        |   |-- osu_alltoallv
        |   |-- osu_barrier
        |   |-- osu_bcast
        |   |-- osu_gather
        |   |-- osu_gatherv
        |   |-- osu_iallgather
        |   |-- osu_iallgatherv
        |   |-- osu_ialltoall
        |   |-- osu_ialltoallv
        |   |-- osu_ialltoallw
        |   |-- osu_ibarrier
        |   |-- osu_ibcast
        |   |-- osu_igather
        |   |-- osu_igatherv
        |   |-- osu_iscatter
        |   |-- osu_iscatterv
        |   |-- osu_reduce
        |   |-- osu_reduce_scatter
        |   |-- osu_scatter
        |   `-- osu_scatterv
        |-- one-sided
        |   |-- osu_acc_latency
        |   |-- osu_cas_latency
        |   |-- osu_fop_latency
        |   |-- osu_get_acc_latency
        |   |-- osu_get_bw
        |   |-- osu_get_latency
        |   |-- osu_put_bibw
        |   |-- osu_put_bw
        |   `-- osu_put_latency
        |-- pt2pt
        |   |-- osu_bibw
        |   |-- osu_bw
        |   |-- osu_latency
        |   |-- osu_latency_mt
        |   |-- osu_mbw_mr
        |   `-- osu_multi_lat
        `-- startup
            |-- osu_hello
            `-- osu_init
\end{lstlisting}


The working of these different benchmarks can be consulted on the \verb|README| file which is downloaded along with the benchmarks. If we do not want to download the \textit{OSU microbenchmarks} package to read this file, it can be also consulted online\cite{osu-microbenchmarks-readme}. \newline
As can be seen, a lot of different benchmarks are available on this package. We will focus our attention on the point-to-point (pt2pt) tests, what will allow us to measure and to evaluate the network's characteristics from the own containers.

\subsection{RAM benchmarks: STREAM}
The \textit{STREAM} benchmark\cite{stream} is a simple synthetic benchmark program that measures sustainable memory bandwidth (in MB/s) and the corresponding computation rate for simple vector kernels. The reason why the \textit{STREAM} benchmark was the selected, and not another one, is because \textit{STREAM} is the de facto industry standard benchmark for measuring sustained memory bandwidth. It uses data sets much larger than the available cache on a system, which avoids large amounts of time devoted waiting for cache misses to be satisfied. Because of this reason, \textit{STREAM} documentation indicates that the value of the \verb|STREAM_ARRAY_SIZE| must be at least four times larger than the combined size of all last level caches used in the run. But this is not the only limitation to define the value of \verb|STREAM_ARRAY_SIZE|: Its size should be large enough so that the "timing calibration" output by the program is at least 20 clock-ticks. Example: most versions of Windows have a 10 millisecond timer granularity. 20 "ticks" at 10 ms/tic is 200 milliseconds. If the chip is capable of 10 GB/s, it moves 2 GB in 200 msec. This means the each array must be at least 1 GB, or 128M elements.


To run the Stream Benchmark on multiprocessor, there are several choices: OpenMP, pthreads, and MPI. Pursuing a global consistency, we will use the MPI version of \textit{STREAM}\footnote{Specifically, stream\_mpi.c, the version of STREAM MPI coded in C, without more reason than the knowledge of the language by the writter of this document.}, instead of its default version, which uses OpenMP. Thank of this version, we will be able to measure the employed RAM under a multiprocessor multinode container environment, using an InfiniBand network, that is, after all, the goal of this research. This will require MPI support installed, an already well-known requirement.


If the reader of this document wishes to go further into the operation of STREAM, online official documentation\cite{stream-documentation} can be consulted. \newline
Turning to our particular case, Finis Terrae II nodes have 24 cores, with the following memory cache structure:
\begin{itemize}
\item L1d cache: 32K
\item L1i cache: 32K
\item L2 cache: 256K
\item L3 cache: 30720K
\end{itemize}


So, attending to the previous limitations to define the value of the \verb|STREAM_ARRAY_SIZE|, it is important to consider the values of the last level cache, as well as the number of available cores. As a plus requirement, added because of the MPI use, two different nodes will be used, in order to ensure the MPI and InfiniBand network utilization. Besides, it is important to reserve the nodes by they full (employing the 24 cores per node and all the available RAM), obtaining the benchmark execution in a blocking way under this environment, without other parallel processes that could generate noise. Doing some arithmetic, we can observe that the sum total of the last level cache per node is 720MiB (30720K = 30MiB per core, having 24 cores). Then, a 720MiB four times size will be needed (2880MiB should be a correct array size), considering a simple-node execution. Since we will execute the benchmark using two nodes, we will have twice the cache: 1440MiB on its last level, obtaining now a size of 5760MB as a great value for the \verb|STREAM_ARRAY_SIZE|. So, I will define the value of the \verb|STREAM_ARRAY_SIZE| as 760000000, which should be a value larger enough for our purposes. 


The other limitation factor, the "timing calibration" output by the program, can not be considered until the program is executed, so it will be ignored at the moment. 


Continuing with the values under the benchmark will be done, it is important to consider that STREAM runs each kernel \verb|NTIMES| times and reports the best result for any iteration after the first. The selected value for this variable will be the default one: 10 times. 


Finally, keep in mind that we must compile the code with optimization and enabling the correct options to be able to use multiprocessing; employing OpenMPI mpicc in our case. Array size can be set at compile time without modifying the source code for the (many) compilers that support preprocessor definitions on the compile line.
\begin{lstlisting}[language=bash,caption={Compilation example employing Singularity containers}]
sudo singularity exec -w CONTAINER_NAME.img mpicc -m64 -o /usr/bin/stream_mpi -O -DSTREAM_ARRAY_SIZE=760000000 stream_mpi.c
\end{lstlisting}


Once the test were executed and the results were obtained, we can analyze them and obtain a series of conclusions. First of all, we will check the values that has to do with the array size and its implications.
\begin{itemize}
\item Total Aggregate Array size = 760000000 (elements)
\item Total Aggregate Memory per array = 5798.3 MiB (= 5.7 GiB).
\item Total Aggregate memory required = 17395.0 MiB (= 17.0 GiB).
\item Data is distributed across 48 MPI ranks
\begin{itemize}
\item   Array size per MPI rank = 15833333 (elements)
\item   Memory per array per MPI rank = 120.8 MiB (= 0.1 GiB).
\item   Total memory per MPI rank = 362.4 MiB (= 0.4 GiB).
\end{itemize}
\end{itemize}


As can be seen, the execution worked over a 760000000 elements array and over 48 different cores, employing MPI. This ensures the wished multinode multicore execution. Due to these parameters, some concrete size values are obtained; e.g. a total aggregate memory value of 17GiB. 


The second important execution output which must be reasoned is the timer granularity, inasmuch as it was previously defined as a limitation factor. The output value for the granularity/precision appears to be 1 microseconds, what will make each test to take on the order of 54269 microseconds (= 54269 timer ticks). Turning back our attention to the needed premises for a great execution, we can check that the array size should be large enough so that the "timing calibration" output by the program is at least 20 clock-ticks. As 54269 >> 20, we can conclude the array size is large enough, and the results will suppose a good study sample. 


The obtained results for the defined test are:
\begin{table}[H]
\centering
\caption{Container STREAM benchmark results}
\label{my-label}
\begin{tabular}{|c|c|l|c|c|c|}
\hline
Function & \multicolumn{2}{c|}{Best rate (MB/s)} & Avg time & Min time & Max time \\ \hline
Copy     & \multicolumn{2}{c|}{155550.7}         & 0.078218 & 0.078174 & 0.078288 \\ \hline
Scale    & \multicolumn{2}{c|}{154837.6}         & 0.078575 & 0.078534 & 0.078641 \\ \hline
Add      & \multicolumn{2}{c|}{177616.6}         & 0.102739 & 0.102693 & 0.102845 \\ \hline
Triad    & \multicolumn{2}{c|}{177573.8}         & 0.102803 & 0.102718 & 0.103148 \\ \hline
\end{tabular}
\end{table}


Continuing the memory benchmark study, a native execution will be done\footnote{In this case, the \texttt{stream\_mpi.c} program were compiled using the GNU compiler gcc/5.3.0, the 1.10.2 version of Open MPI, and enabling the optimization compiling flags.}, in order to compare both executions, the containerized one and the native one. Obviously, the parameters under the native execution will be done are exactly the same than those which were used in the previous containerized execution. That is why they will not be analyzed again. The obtained results under the native execution are:
\begin{table}[H]
\centering
\caption{Native STREAM benchmark results}
\label{my-label}
\begin{tabular}{|c|c|l|c|c|c|}
\hline
Function & \multicolumn{2}{c|}{Best rate (MB/s)} & Avg time & Min time & Max time \\ \hline
Copy     & \multicolumn{2}{c|}{155478.6}         & 0.078266 & 0.078210 & 0.078386 \\ \hline
Scale    & \multicolumn{2}{c|}{154717.4}         & 0.078623 & 0.078595 & 0.078691 \\ \hline
Add      & \multicolumn{2}{c|}{177729.3}         & 0.102662 & 0.102628 & 0.102683 \\ \hline
Triad    & \multicolumn{2}{c|}{177710.3}         & 0.102694 & 0.102639 & 0.102851 \\ \hline
\end{tabular}
\end{table}


Note that the test results have an avg error less than 1.000000e-13 on all three arrays for both cases, what make them a reliable source. 


Now that all the results were obtained, we can easily compare them. Starting with those related to the execution times, observe that they present values with differences that hover around the magnitude of 1.0e-4 seconds. In addition, there is no execution that always obtains the best results (less time), but in some cases this value is obtained by the native execution and in others by the containerized solution. Looking now at the bandwidth rate, there is no a clear difference between the results to assign a solution better than the other one. \newline 


So, after all the done tests and the obtained results, we can say that a containerized solution will make use of the machine memory that will come very close to the use that would be made under a native execution. \textbf{Native and container executions are comparable in terms of memory.}

\subsection{CPU benchmarks: HPL}
\textit{HPL}\cite{HPL}, a portable implementation of the \textit{High-Performance Linpack Benchmark} for distributed-memory computers, is a software package that solves a random dense linear system in double precision arithmetic on distributed-memory computers.


The \textit{HPL} package provides a testing and timing program to quantify the accuracy of the obtained solution as well as the time it took to compute it. It requires the availibility on the system of an implementation of the Message Passing Interface (MPI). An implementation of either the Basic Linear Algebra Subprograms BLAS or the Vector Signal Image Processing Library VSIPL is also needed. These requisites make \textit{HPL} an excelent CPU usage measurer candidate for our concrete research.


The end of this benchmark it is not to reach the infrastructure peak of performance, but what is pursued is to verify the functioning and to check
the correct performance mixing different MPI versions inside-outside containers to make a comparison with an one-to-one inside-outside MPI versions execution, already done.


What will be done is to reproduce a series of executions that were already made in the cluster, under an one-to-one inside-outside MPI versions. Thus, once all the results are obtained, both behaviors will be compared, and it will be reasoned if the solution with mixing MPI versions containers supposes, if it exists, a reasonable delay.


In order to get a battery of results a little varied, what will be done is to execute these benchmarks with an upward focus. By this I mean that I will reproduce its execution making use of a greater number of processors each time. Computations will be run in 1, 2, 4, 8, 16 and 32 nodes at FinisTerrae II. For every node increment, the problem's size will increase too, in order to take always approximately 80-90\% of available memory of the involved nodes. This is what is called a scalability test weak. \newline

The results of the one-to-one inside-outside MPI versions weak scaling tests show an increase of the aggregated performance as we increase the number of nodes involved. Looking at the results we can also see that the performance per node is maintained almost immutable along the different executions. These results are also very close to the expected theoretical values.

Figure \nameref{Weak scaling test 1} shows the performance (logarithmic scale) of the weak scaling test depending on the number of nodes involved in the computation.

To provide another view of the obtained values, they can also be seen in figure \nameref{Weak scaling test 2}, with a different scale for the vertical axis (GFlops).

\begin{figure}[H]
\centering
     \includegraphics[width=1.0\textwidth]{CPU-graph-1}
      \caption{Weak scaling test 1}
       \label{Weak scaling test 1}
\end{figure}

\begin{figure}[H]
\centering
     \includegraphics[width=1.0\textwidth]{CPU-graph-2}
      \caption{Weak scaling test 2}
       \label{Weak scaling test 2}
\end{figure}

Comparing those results with the inside-outside mixed MPI execution, it is clear that both have the same trend. However, in the mix test, a little delay is present. At this point, it is important to clarify that the test has been performed only once (a single execution), due to the large computational time that is required for this. Therefore, in the absence of comparisons with other executions, it is possible that this particular case has produced factors that generate noise, thus causing this delay. So, if we look at figures \nameref{Weak scaling test 3} and \nameref{Weak scaling test 4}, we will be able to appreciate this little delay, especially on the 32 nodes execution.

\begin{figure}[H]
\centering
     \includegraphics[width=1.0\textwidth]{CPU-graph-3}
      \caption{Weak scaling test 3}
       \label{Weak scaling test 3}
\end{figure}

\begin{figure}[H]
\centering
     \includegraphics[width=1.0\textwidth]{CPU-graph-4}
      \caption{Weak scaling test 4}
       \label{Weak scaling test 4}
\end{figure}

Therefore, despite the fact that the execution with inside-outside mixed MPI has presented a small delay, this is not of a great magnitude. In addition, this delay may occur only as a consequence of some uncontrolled noise. Therefore, we can say that the \textbf{execution with inside-outside mixed MPI is a good solution in terms of computational time, although it may not be the best.}

\section{Discussion 1/2-1 page}
Ut eget est sem. Duis suscipit turpis sed orci mattis, sed tempus sapien rhoncus. Aliquam at ex nulla. Suspendisse et lorem ornare, tincidunt eros et, dictum metus. Etiam auctor elementum enim. Fusce in convallis ex, at sagittis elit. Suspendisse auctor gravida molestie. In mi tellus, tristique quis mi sed, blandit lobortis libero. 


\begin{thebibliography}{9}
\bibitem{osu-microbenchmarks}
  OSU Micro Benchmarks [Internet] - MVAPICH: MPI over InfiniBand, Omni-Path, Ethernet/iWARP, and RoCE [Quoted July 24, 2017]. 
Recovered from: \url{<http://mvapich.cse.ohio-state.edu/userguide/virt/#_osu_micro_benchmarks>}

\bibitem{osu-microbenchmarks-readme}
  OSU Micro Benchmarks README file [Internet] - MVAPICH: MPI over InfiniBand, Omni-Path, Ethernet/iWARP, and RoCE [Quoted July 24, 2017].
Recovered from: \url{<http://mvapich.cse.ohio-state.edu/static/media/mvapich/README-OMB.txt>}

\bibitem{HPL}
  HPL - A Portable Implementation of the High-Performance Linpack Benchmark for Distributed-Memory Computers [Internet] - The Innovative Computing Laboratory (ICL) of the University of Tennesse [Quoted July 28, 2017]. 
Recovered from: \url{<http://www.netlib.org/benchmark/hpl/>}

\bibitem{stream}
  STREAM: Sustainable Memory Bandwidth in High Performance Computers [Internet] [Quoted July 28, 2017]. 
Recovered from: \url{<https://www.cs.virginia.edu/stream/>}

\bibitem{stream-documentation}
  STREAM ref. - STREAM: Sustainable Memory Bandwidth in High Performance Computers [Internet] [Quoted July 28, 2017]. 
Recovered from: \url{<https://www.cs.virginia.edu/stream/ref.html>}

\end{thebibliography}
\end{document}
